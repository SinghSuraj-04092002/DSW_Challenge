{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMOmqQrkPw3KQzZfqXkWWQy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ong7DaDkPTby","executionInfo":{"status":"ok","timestamp":1707824067328,"user_tz":-330,"elapsed":95214,"user":{"displayName":"Suraj Singh","userId":"15965593826219083362"}},"outputId":"7a253933-4660-444c-aa38-b6b7c6175d32"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install keras==2.12.0\n","import pandas as pd\n","import numpy as np\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n","import warnings\n","warnings.filterwarnings('ignore')\n","import pandas as pd\n","import numpy as np\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a8WJudDJPys-","executionInfo":{"status":"ok","timestamp":1707824109042,"user_tz":-330,"elapsed":17943,"user":{"displayName":"Suraj Singh","userId":"15965593826219083362"}},"outputId":"e7453e6d-9549-41cc-8cb3-e83307f39045"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting keras==2.12.0\n","  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: keras\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.15.0\n","    Uninstalling keras-2.15.0:\n","      Successfully uninstalled keras-2.15.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 2.12.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-2.12.0\n"]}]},{"cell_type":"code","source":["class ANNClassifier:\n","    def __init__(self):                   #initializing variables\n","        self.pipeline = None\n","        self.label_encoder1 = None\n","        self.label_encoder2 = None\n","        self.label_encoder3 = None\n","        self.scaler = None\n","        self.x_train = None\n","        self.x_test = None\n","        self.y_encoded_train = None\n","        self.y_encoded_test = None\n","\n","    def load(self, file_path):                    # Loading data stage\n","        self.data = pd.read_csv(\"/content/drive/MyDrive/DSW_Internship_Task/historic.csv\")\n","\n","    def preprocess(self):  # preprocessing stage\n","\n","        x = self.data.drop(['success_indicator', 'item_no'], axis=1)  # separating dependent and independent variables\n","        y = self.data['success_indicator']\n","\n","        # here we will encode all text categorical data to numerical categorical data\n","        self.label_encoder1 = LabelEncoder()\n","        x['category_encoded'] = self.label_encoder1.fit_transform(x['category'])\n","        x.drop('category', axis=1, inplace=True)\n","\n","        self.label_encoder2 = LabelEncoder()\n","        x['main_promotion_encoded'] = self.label_encoder2.fit_transform(x['main_promotion'])\n","        x.drop('main_promotion', axis=1, inplace=True)\n","\n","        self.label_encoder3 = LabelEncoder()\n","        x['color_encoded'] = self.label_encoder3.fit_transform(x['color'])\n","        x.drop('color', axis=1, inplace=True)\n","\n","        # here we will convert stars rating features into bins where rating <=3 will be 0 and rating>3 will be 1\n","        x['stars'] = np.where(x['stars'] <= 3, 0, x['stars'])\n","        x['stars'] = np.where(x['stars'] > 3, 1, x['stars'])\n","\n","        # encoding category where 'flop'= 0 and 'top'=1\n","        label_encoder4 = LabelEncoder()\n","        y_encoded = label_encoder4.fit_transform(y)\n","        y_encoded = np.where(y_encoded == label_encoder4.classes_.tolist().index('flop'), 0, y_encoded)\n","        y_encoded = np.where(y_encoded == label_encoder4.classes_.tolist().index('top'), 1, y_encoded)\n","\n","        self.scaler = StandardScaler()\n","        x_train = self.scaler.fit_transform(x)\n","\n","        # here we will split the data into training and testing purpose\n","        self.x_train, self.x_test, self.y_encoded_train, self.y_encoded_test = train_test_split(x_train, y_encoded,\n","                                                                                                test_size=0.2,\n","                                                                                                random_state=77)\n","\n","    def create_model(self):\n","        model = Sequential()\n","        model.add(Dense(10, input_dim=4, activation='relu'))\n","        model.add(Dense(1, activation='sigmoid'))\n","        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","        return model\n","\n","    def fit(self):\n","        # Creating KerasClassifier by using above model\n","        keras_model = KerasClassifier(build_fn=self.create_model, epochs=10, batch_size=32, verbose=0)\n","\n","        # Creating sklearn pipeline\n","        self.pipeline = Pipeline([\n","            ('scaler', StandardScaler()),  # Preprocessing step, if needed\n","            ('classifier', keras_model)  # Keras model as the classifier\n","        ])\n","\n","        # here we will fit the pipeline on the training data\n","        self.pipeline.fit(self.x_train, self.y_encoded_train)\n","\n","    def predict(self):\n","        # we will use pipeline to make predictions\n","        return self.pipeline.predict(self.x_test)\n","\n","    def evaluate(self):\n","\n","        y_pred = self.predict()\n","        accuracy = accuracy_score(self.y_encoded_test, y_pred)\n","\n","        precision = precision_score(self.y_encoded_test,y_pred)\n","        recall = recall_score(self.y_encoded_test, y_pred)\n","        f1 = f1_score(self.y_encoded_test, y_pred)\n","\n","        print(\"Accuracy with ann_classifier is:\", accuracy)\n","        print(\"precision with  ann_classifier model is :\", precision)  # Model evaluation stage\n","        print(\"recall with ann_classifier model is:\", recall)\n","        print(\"f1 Score with ann_classifier model is :\", f1)\n","\n","   # function to load unlabelled file i.e, 'prediction_input.csv'\n","    def load_test_file(self, file_path):                                      #loading stage for testing file\n","        self.input_data = pd.read_csv(file_path)\n","        return self.input_data\n","\n","        # this function will process input data such as removing the unwanted features and encoding categorical features\n","    def test_data_preprocessor(self):\n","\n","        self.input_data_processed = self.input_data.drop(['item_no'], axis=1)           #preprocessing stage for\n","\n","        self.input_data_processed['category_encoded'] = pipeline.label_encoder1.transform(self.input_data_processed['category'])\n","        self.input_data_processed.drop('category', axis=1, inplace=True)\n","\n","        self.input_data_processed['main_promotion_encoded'] = pipeline.label_encoder2.transform(self.input_data_processed['main_promotion'])\n","        self.input_data_processed.drop('main_promotion', axis=1, inplace=True)\n","\n","        self.input_data_processed['color_encoded'] = pipeline.label_encoder3.transform(self.input_data_processed['color'])\n","        self.input_data_processed.drop('color', axis=1, inplace=True)\n","\n","        # here we will convert star rating into bins and designate star <= 3 into 0 and star rating> 3 =1\n","        self.input_data_processed['stars'] = np.where(self.input_data_processed['stars'] <= 3, 0, self.input_data_processed['stars'])\n","        self.input_data_processed['stars'] = np.where(self.input_data_processed['stars'] > 3, 1, self.input_data_processed['stars'])\n","\n","        self.input_data_processed = pipeline.scaler.transform(self.input_data_processed)\n","\n","        return self.input_data_processed\n","\n","\n","        # this function will predict dependent variable based on independent variable present in prediction_input file\n","            # and give a an array of 2000 row in form of 1 , 0 where 1 = 'TOP' AND 0 = 'FLOP'\n","    def predict_for_test_data(self):\n","        output = self.pipeline.predict(self.input_data_processed)\n","        return output\n","\n"],"metadata":{"id":"Y1ValZAHP-kt","executionInfo":{"status":"ok","timestamp":1707824129927,"user_tz":-330,"elapsed":431,"user":{"displayName":"Suraj Singh","userId":"15965593826219083362"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["pipeline = ANNClassifier()\n","pipeline.load('/content/drive/MyDrive/DSW_Internship_Task/historic.csv')\n","pipeline.preprocess()\n","pipeline.create_model()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q2UJz47UQDMS","executionInfo":{"status":"ok","timestamp":1707824145463,"user_tz":-330,"elapsed":1091,"user":{"displayName":"Suraj Singh","userId":"15965593826219083362"}},"outputId":"ac500162-f7d7-440b-d575-1572253abd92"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras.engine.sequential.Sequential at 0x799fddd769b0>"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["pipeline.fit()\n","pipeline.predict()\n","pipeline.evaluate()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"371AY4EwQG4t","executionInfo":{"status":"ok","timestamp":1707824164221,"user_tz":-330,"elapsed":7017,"user":{"displayName":"Suraj Singh","userId":"15965593826219083362"}},"outputId":"36d27b30-a5e5-4bd4-d4bb-33493511c97a"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["50/50 [==============================] - 0s 1ms/step\n","50/50 [==============================] - 0s 1ms/step\n","Accuracy with ann_classifier is: 0.791875\n","precision with  ann_classifier model is : 0.8086040386303776\n","recall with ann_classifier model is: 0.888996138996139\n","f1 Score with ann_classifier model is : 0.8468965517241379\n"]}]},{"cell_type":"code","source":["pipeline.load_test_file('/content/drive/MyDrive/DSW_Internship_Task/prediction_input.csv')\n","pipeline.test_data_preprocessor()\n"],"metadata":{"id":"H5FntDCeQL54","executionInfo":{"status":"ok","timestamp":1707824179387,"user_tz":-330,"elapsed":558,"user":{"displayName":"Suraj Singh","userId":"15965593826219083362"}},"outputId":"661141bf-cf4a-4c57-a9dc-c252ee7c55a2","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0.71814041,  0.14679292, -1.21487945, -1.09392977],\n","       [-1.39248534, -0.43949933,  1.41449261,  1.64581764],\n","       [-1.39248534,  1.31937742, -1.21487945, -0.40899292],\n","       ...,\n","       [-1.39248534, -0.43949933, -1.21487945,  0.27594393],\n","       [-1.39248534, -1.61208383,  1.41449261, -0.06652449],\n","       [-1.39248534,  0.73308517, -0.33842209, -0.06652449]])"]},"metadata":{},"execution_count":6}]}]}